{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd67802f",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25545cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve, average_precision_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550c882",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "dfd301c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>Cat_175</th>\n",
       "      <th>Cat_176</th>\n",
       "      <th>Cat_177</th>\n",
       "      <th>Cat_178</th>\n",
       "      <th>Cat_179</th>\n",
       "      <th>Cat_180</th>\n",
       "      <th>Cat_181</th>\n",
       "      <th>Cat_182</th>\n",
       "      <th>Cat_183</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ps_ind_01  ps_ind_03  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  \\\n",
       "0   1          4          5              0              0              0   \n",
       "1   2          0          4              1              0              0   \n",
       "2   3          5          3              0              0              1   \n",
       "3   4          2          6              0              1              0   \n",
       "4   5          1          4              1              0              0   \n",
       "\n",
       "   ps_ind_09_bin  ps_ind_10_bin  ps_ind_11_bin  ps_ind_12_bin  ...  Cat_175  \\\n",
       "0              1              0              0              0  ...        0   \n",
       "1              0              0              0              0  ...        0   \n",
       "2              0              0              0              0  ...        0   \n",
       "3              0              0              0              0  ...        0   \n",
       "4              0              0              0              0  ...        0   \n",
       "\n",
       "   Cat_176  Cat_177  Cat_178  Cat_179  Cat_180  Cat_181  Cat_182  Cat_183  \\\n",
       "0        0        0        0        0        0        0        0        1   \n",
       "1        0        0        0        0        0        0        0        1   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       1  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 225 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train = pd.read_csv('train.csv')\n",
    "raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ca667e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>Cat_174</th>\n",
       "      <th>Cat_175</th>\n",
       "      <th>Cat_176</th>\n",
       "      <th>Cat_177</th>\n",
       "      <th>Cat_178</th>\n",
       "      <th>Cat_179</th>\n",
       "      <th>Cat_180</th>\n",
       "      <th>Cat_181</th>\n",
       "      <th>Cat_182</th>\n",
       "      <th>Cat_183</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ps_ind_01  ps_ind_03  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  \\\n",
       "0   1          5          6              0              1              0   \n",
       "1   2          6          6              0              1              0   \n",
       "2   3          3          1              1              0              0   \n",
       "3   4          5          6              1              0              0   \n",
       "4   5          0          1              1              0              0   \n",
       "\n",
       "   ps_ind_09_bin  ps_ind_10_bin  ps_ind_11_bin  ps_ind_12_bin  ...  Cat_174  \\\n",
       "0              0              0              0              0  ...        0   \n",
       "1              0              0              0              0  ...        0   \n",
       "2              0              0              0              0  ...        0   \n",
       "3              0              0              0              0  ...        0   \n",
       "4              0              0              0              0  ...        0   \n",
       "\n",
       "   Cat_175  Cat_176  Cat_177  Cat_178  Cat_179  Cat_180  Cat_181  Cat_182  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        1   \n",
       "\n",
       "   Cat_183  \n",
       "0        1  \n",
       "1        1  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 224 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test = pd.read_csv('test.csv')\n",
    "raw_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3418df3a",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "95cee74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 225 entries, id to target\n",
      "dtypes: float64(7), int64(218)\n",
      "memory usage: 85.8 MB\n"
     ]
    }
   ],
   "source": [
    "raw_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5e882089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_car_13</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_car_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.957862</td>\n",
       "      <td>0.424264</td>\n",
       "      <td>1.173117</td>\n",
       "      <td>0.438292</td>\n",
       "      <td>3.605551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583095</td>\n",
       "      <td>0.446990</td>\n",
       "      <td>0.675776</td>\n",
       "      <td>0.344964</td>\n",
       "      <td>2.236068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.775806</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.706405</td>\n",
       "      <td>0.339116</td>\n",
       "      <td>2.645751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.112430</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>1.678110</td>\n",
       "      <td>0.532917</td>\n",
       "      <td>3.605551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.716764</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.938700</td>\n",
       "      <td>0.401746</td>\n",
       "      <td>3.741657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ps_reg_01  ps_reg_02  ps_reg_03  ps_car_12  ps_car_13  ps_car_14  ps_car_15\n",
       "0        0.9        0.4   0.957862   0.424264   1.173117   0.438292   3.605551\n",
       "1        0.4        0.0   0.583095   0.446990   0.675776   0.344964   2.236068\n",
       "2        0.4        0.0   0.775806   0.447214   0.706405   0.339116   2.645751\n",
       "3        0.4        0.5   1.112430   0.547723   1.678110   0.532917   3.605551\n",
       "4        0.6        0.2   0.716764   0.400000   0.938700   0.401746   3.741657"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train.select_dtypes(include='float').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3e57223f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>Cat_174</th>\n",
       "      <th>Cat_175</th>\n",
       "      <th>Cat_176</th>\n",
       "      <th>Cat_177</th>\n",
       "      <th>Cat_178</th>\n",
       "      <th>Cat_179</th>\n",
       "      <th>Cat_180</th>\n",
       "      <th>Cat_181</th>\n",
       "      <th>Cat_182</th>\n",
       "      <th>Cat_183</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.901700</td>\n",
       "      <td>4.410700</td>\n",
       "      <td>0.392260</td>\n",
       "      <td>0.256080</td>\n",
       "      <td>0.16504</td>\n",
       "      <td>0.18662</td>\n",
       "      <td>0.00038</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.009580</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>0.00338</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.020220</td>\n",
       "      <td>0.007440</td>\n",
       "      <td>0.012660</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>0.041020</td>\n",
       "      <td>0.141660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.980383</td>\n",
       "      <td>2.702897</td>\n",
       "      <td>0.488259</td>\n",
       "      <td>0.436471</td>\n",
       "      <td>0.37122</td>\n",
       "      <td>0.38961</td>\n",
       "      <td>0.01949</td>\n",
       "      <td>0.045341</td>\n",
       "      <td>0.097408</td>\n",
       "      <td>0.030645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081094</td>\n",
       "      <td>0.05804</td>\n",
       "      <td>0.049938</td>\n",
       "      <td>0.071233</td>\n",
       "      <td>0.140754</td>\n",
       "      <td>0.085935</td>\n",
       "      <td>0.111803</td>\n",
       "      <td>0.057869</td>\n",
       "      <td>0.198338</td>\n",
       "      <td>0.348705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ps_ind_01     ps_ind_03  ps_ind_06_bin  ps_ind_07_bin  \\\n",
       "count  50000.000000  50000.000000   50000.000000   50000.000000   \n",
       "mean       1.901700      4.410700       0.392260       0.256080   \n",
       "std        1.980383      2.702897       0.488259       0.436471   \n",
       "min        0.000000      0.000000       0.000000       0.000000   \n",
       "25%        0.000000      2.000000       0.000000       0.000000   \n",
       "50%        1.000000      4.000000       0.000000       0.000000   \n",
       "75%        3.000000      6.000000       1.000000       1.000000   \n",
       "max        7.000000     11.000000       1.000000       1.000000   \n",
       "\n",
       "       ps_ind_08_bin  ps_ind_09_bin  ps_ind_10_bin  ps_ind_11_bin  \\\n",
       "count    50000.00000    50000.00000    50000.00000   50000.000000   \n",
       "mean         0.16504        0.18662        0.00038       0.002060   \n",
       "std          0.37122        0.38961        0.01949       0.045341   \n",
       "min          0.00000        0.00000        0.00000       0.000000   \n",
       "25%          0.00000        0.00000        0.00000       0.000000   \n",
       "50%          0.00000        0.00000        0.00000       0.000000   \n",
       "75%          0.00000        0.00000        0.00000       0.000000   \n",
       "max          1.00000        1.00000        1.00000       1.000000   \n",
       "\n",
       "       ps_ind_12_bin  ps_ind_13_bin  ...       Cat_174      Cat_175  \\\n",
       "count   50000.000000   50000.000000  ...  50000.000000  50000.00000   \n",
       "mean        0.009580       0.000940  ...      0.006620      0.00338   \n",
       "std         0.097408       0.030645  ...      0.081094      0.05804   \n",
       "min         0.000000       0.000000  ...      0.000000      0.00000   \n",
       "25%         0.000000       0.000000  ...      0.000000      0.00000   \n",
       "50%         0.000000       0.000000  ...      0.000000      0.00000   \n",
       "75%         0.000000       0.000000  ...      0.000000      0.00000   \n",
       "max         1.000000       1.000000  ...      1.000000      1.00000   \n",
       "\n",
       "            Cat_176       Cat_177       Cat_178       Cat_179       Cat_180  \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean       0.002500      0.005100      0.020220      0.007440      0.012660   \n",
       "std        0.049938      0.071233      0.140754      0.085935      0.111803   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "            Cat_181       Cat_182       Cat_183  \n",
       "count  50000.000000  50000.000000  50000.000000  \n",
       "mean       0.003360      0.041020      0.141660  \n",
       "std        0.057869      0.198338      0.348705  \n",
       "min        0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000  \n",
       "50%        0.000000      0.000000      0.000000  \n",
       "75%        0.000000      0.000000      0.000000  \n",
       "max        1.000000      1.000000      1.000000  \n",
       "\n",
       "[8 rows x 223 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train.drop(columns=['id','target']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8241e5",
   "metadata": {},
   "source": [
    "## What is the balance of class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9dbb940d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.96356\n",
       "1    0.03644\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284398ed",
   "metadata": {},
   "source": [
    "As we can see there is unbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acb971f",
   "metadata": {},
   "source": [
    "## How many features for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "45ab3fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'ps_ind_01',\n",
       " 'ps_ind_03',\n",
       " 'ps_ind_06_bin',\n",
       " 'ps_ind_07_bin',\n",
       " 'ps_ind_08_bin',\n",
       " 'ps_ind_09_bin',\n",
       " 'ps_ind_10_bin',\n",
       " 'ps_ind_11_bin',\n",
       " 'ps_ind_12_bin',\n",
       " 'ps_ind_13_bin',\n",
       " 'ps_ind_14',\n",
       " 'ps_ind_15',\n",
       " 'ps_ind_16_bin',\n",
       " 'ps_ind_17_bin',\n",
       " 'ps_ind_18_bin',\n",
       " 'ps_reg_01',\n",
       " 'ps_reg_02',\n",
       " 'ps_reg_03',\n",
       " 'ps_car_11',\n",
       " 'ps_car_12',\n",
       " 'ps_car_13',\n",
       " 'ps_car_14',\n",
       " 'ps_car_15',\n",
       " 'missing',\n",
       " 'ps_ind_02_cat_count',\n",
       " 'ps_ind_04_cat_count',\n",
       " 'ps_ind_05_cat_count',\n",
       " 'ps_car_01_cat_count',\n",
       " 'ps_car_02_cat_count',\n",
       " 'ps_car_03_cat_count',\n",
       " 'ps_car_04_cat_count',\n",
       " 'ps_car_05_cat_count',\n",
       " 'ps_car_06_cat_count',\n",
       " 'ps_car_07_cat_count',\n",
       " 'ps_car_08_cat_count',\n",
       " 'ps_car_09_cat_count',\n",
       " 'ps_car_10_cat_count',\n",
       " 'ps_car_11_cat_count',\n",
       " 'new_ind_count',\n",
       " 'Cat_0',\n",
       " 'Cat_1',\n",
       " 'Cat_2',\n",
       " 'Cat_3',\n",
       " 'Cat_4',\n",
       " 'Cat_5',\n",
       " 'Cat_6',\n",
       " 'Cat_7',\n",
       " 'Cat_8',\n",
       " 'Cat_9',\n",
       " 'Cat_10',\n",
       " 'Cat_11',\n",
       " 'Cat_12',\n",
       " 'Cat_13',\n",
       " 'Cat_14',\n",
       " 'Cat_15',\n",
       " 'Cat_16',\n",
       " 'Cat_17',\n",
       " 'Cat_18',\n",
       " 'Cat_19',\n",
       " 'Cat_20',\n",
       " 'Cat_21',\n",
       " 'Cat_22',\n",
       " 'Cat_23',\n",
       " 'Cat_24',\n",
       " 'Cat_25',\n",
       " 'Cat_26',\n",
       " 'Cat_27',\n",
       " 'Cat_28',\n",
       " 'Cat_29',\n",
       " 'Cat_30',\n",
       " 'Cat_31',\n",
       " 'Cat_32',\n",
       " 'Cat_33',\n",
       " 'Cat_34',\n",
       " 'Cat_35',\n",
       " 'Cat_36',\n",
       " 'Cat_37',\n",
       " 'Cat_38',\n",
       " 'Cat_39',\n",
       " 'Cat_40',\n",
       " 'Cat_41',\n",
       " 'Cat_42',\n",
       " 'Cat_43',\n",
       " 'Cat_44',\n",
       " 'Cat_45',\n",
       " 'Cat_46',\n",
       " 'Cat_47',\n",
       " 'Cat_48',\n",
       " 'Cat_49',\n",
       " 'Cat_50',\n",
       " 'Cat_51',\n",
       " 'Cat_52',\n",
       " 'Cat_53',\n",
       " 'Cat_54',\n",
       " 'Cat_55',\n",
       " 'Cat_56',\n",
       " 'Cat_57',\n",
       " 'Cat_58',\n",
       " 'Cat_59',\n",
       " 'Cat_60',\n",
       " 'Cat_61',\n",
       " 'Cat_62',\n",
       " 'Cat_63',\n",
       " 'Cat_64',\n",
       " 'Cat_65',\n",
       " 'Cat_66',\n",
       " 'Cat_67',\n",
       " 'Cat_68',\n",
       " 'Cat_69',\n",
       " 'Cat_70',\n",
       " 'Cat_71',\n",
       " 'Cat_72',\n",
       " 'Cat_73',\n",
       " 'Cat_74',\n",
       " 'Cat_75',\n",
       " 'Cat_76',\n",
       " 'Cat_77',\n",
       " 'Cat_78',\n",
       " 'Cat_79',\n",
       " 'Cat_80',\n",
       " 'Cat_81',\n",
       " 'Cat_82',\n",
       " 'Cat_83',\n",
       " 'Cat_84',\n",
       " 'Cat_85',\n",
       " 'Cat_86',\n",
       " 'Cat_87',\n",
       " 'Cat_88',\n",
       " 'Cat_89',\n",
       " 'Cat_90',\n",
       " 'Cat_91',\n",
       " 'Cat_92',\n",
       " 'Cat_93',\n",
       " 'Cat_94',\n",
       " 'Cat_95',\n",
       " 'Cat_96',\n",
       " 'Cat_97',\n",
       " 'Cat_98',\n",
       " 'Cat_99',\n",
       " 'Cat_100',\n",
       " 'Cat_101',\n",
       " 'Cat_102',\n",
       " 'Cat_103',\n",
       " 'Cat_104',\n",
       " 'Cat_105',\n",
       " 'Cat_106',\n",
       " 'Cat_107',\n",
       " 'Cat_108',\n",
       " 'Cat_109',\n",
       " 'Cat_110',\n",
       " 'Cat_111',\n",
       " 'Cat_112',\n",
       " 'Cat_113',\n",
       " 'Cat_114',\n",
       " 'Cat_115',\n",
       " 'Cat_116',\n",
       " 'Cat_117',\n",
       " 'Cat_118',\n",
       " 'Cat_119',\n",
       " 'Cat_120',\n",
       " 'Cat_121',\n",
       " 'Cat_122',\n",
       " 'Cat_123',\n",
       " 'Cat_124',\n",
       " 'Cat_125',\n",
       " 'Cat_126',\n",
       " 'Cat_127',\n",
       " 'Cat_128',\n",
       " 'Cat_129',\n",
       " 'Cat_130',\n",
       " 'Cat_131',\n",
       " 'Cat_132',\n",
       " 'Cat_133',\n",
       " 'Cat_134',\n",
       " 'Cat_135',\n",
       " 'Cat_136',\n",
       " 'Cat_137',\n",
       " 'Cat_138',\n",
       " 'Cat_139',\n",
       " 'Cat_140',\n",
       " 'Cat_141',\n",
       " 'Cat_142',\n",
       " 'Cat_143',\n",
       " 'Cat_144',\n",
       " 'Cat_145',\n",
       " 'Cat_146',\n",
       " 'Cat_147',\n",
       " 'Cat_148',\n",
       " 'Cat_149',\n",
       " 'Cat_150',\n",
       " 'Cat_151',\n",
       " 'Cat_152',\n",
       " 'Cat_153',\n",
       " 'Cat_154',\n",
       " 'Cat_155',\n",
       " 'Cat_156',\n",
       " 'Cat_157',\n",
       " 'Cat_158',\n",
       " 'Cat_159',\n",
       " 'Cat_160',\n",
       " 'Cat_161',\n",
       " 'Cat_162',\n",
       " 'Cat_163',\n",
       " 'Cat_164',\n",
       " 'Cat_165',\n",
       " 'Cat_166',\n",
       " 'Cat_167',\n",
       " 'Cat_168',\n",
       " 'Cat_169',\n",
       " 'Cat_170',\n",
       " 'Cat_171',\n",
       " 'Cat_172',\n",
       " 'Cat_173',\n",
       " 'Cat_174',\n",
       " 'Cat_175',\n",
       " 'Cat_176',\n",
       " 'Cat_177',\n",
       " 'Cat_178',\n",
       " 'Cat_179',\n",
       " 'Cat_180',\n",
       " 'Cat_181',\n",
       " 'Cat_182',\n",
       " 'Cat_183',\n",
       " 'target']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cd42de68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ps_ind__cat_count',\n",
       " 'new_ind_count',\n",
       " 'Cat_',\n",
       " 'missing',\n",
       " 'ps_ind__bin',\n",
       " 'ps_reg_',\n",
       " 'id',\n",
       " 'target',\n",
       " 'ps_ind_',\n",
       " 'ps_car__cat_count',\n",
       " 'ps_car_']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_strings = [re.sub(r'\\d+', '', s) for s in raw_train.columns]\n",
    "\n",
    "unique_cols = list(set(clean_strings))\n",
    "\n",
    "unique_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7293812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'ps_ind__cat_count' there are 0 columns\n",
      "For 'new_ind_count' there are 1 columns\n",
      "For 'Cat_' there are 184 columns\n",
      "For 'missing' there are 1 columns\n",
      "For 'ps_ind__bin' there are 0 columns\n",
      "For 'ps_reg_' there are 3 columns\n",
      "For 'id' there are 1 columns\n",
      "For 'target' there are 1 columns\n",
      "For 'ps_ind_' there are 18 columns\n",
      "For 'ps_car__cat_count' there are 0 columns\n",
      "For 'ps_car_' there are 16 columns\n",
      "Total 225 columns\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for col in unique_cols:\n",
    "    matching_cols = list(filter(lambda column: col in str(column), raw_train.columns))\n",
    "    num = len(matching_cols)\n",
    "    s += num\n",
    "    print(f\"For '{col}' there are {num} columns\")\n",
    "print(f\"Total {s} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab09ce2",
   "metadata": {},
   "source": [
    "## How many nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b1478800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634b4235",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "57834f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_train = raw_train.copy()\n",
    "fe_test = raw_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613b9ff4",
   "metadata": {},
   "source": [
    "## Change to category type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "3353c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_category = fe_train.columns.to_list()[:39] # until Cat_*\n",
    "\n",
    "for col in col_to_category:\n",
    "    if fe_train[col].dtype == 'int' and fe_train[col].nunique() < 10 and fe_train[col].nunique() > 2:\n",
    "        fe_train[col] = fe_train[col].astype('category')\n",
    "        fe_test[col] = fe_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7175fe",
   "metadata": {},
   "source": [
    "## Sum of Cat features with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "48029952",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [col for col in fe_train.columns if 'Cat_' in col]\n",
    "fe_train['num_cat_true'] = fe_train[cat_cols].sum(axis=1)\n",
    "fe_test['num_cat_true'] = fe_test[cat_cols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0e3ae3",
   "metadata": {},
   "source": [
    "## Sum of Bin features with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "e71948b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_cols = [col for col in fe_train.columns if 'bin' in col]\n",
    "fe_train['sum_bin'] = fe_train[bin_cols].sum(axis=1)\n",
    "fe_test['sum_bin'] = fe_test[bin_cols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a51e0a",
   "metadata": {},
   "source": [
    "# Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "1912fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fe_train.drop(columns=['target'])\n",
    "y = fe_train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594e1ee6",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8632f2",
   "metadata": {},
   "source": [
    "make all samples with target 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f18f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.DataFrame(data={'id':raw_test['id'], 'target': np.repeat(1, raw_test.shape[0])})\n",
    "base.to_csv(\"baseline_exam.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51442a8d",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "b358185e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(15.0)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial):\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 1000, 3000),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 8, 17),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 15, 75),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
    "        'force_col_wise': True,\n",
    "        'objective': 'binary',\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 23\n",
    "    }\n",
    "    \n",
    "    model = lightgbm.LGBMClassifier(**params)\n",
    "    \n",
    "    splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=21)\n",
    "\n",
    "    aucs = []\n",
    "\n",
    "    for _, (train_index, valid_index) in enumerate(splitter.split(X, y)):\n",
    "\n",
    "        X_train , y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_valid, y_valid = X.iloc[valid_index], y.iloc[valid_index]\n",
    "\n",
    "\n",
    "        model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_valid, y_valid)],\n",
    "                  eval_metric='auc',\n",
    "                  callbacks=[lightgbm.early_stopping(25, verbose=False),\n",
    "                              lightgbm.log_evaluation(period=0, show_stdv=False)])\n",
    "        \n",
    "        y_pred_proba = model.predict_proba(X_valid)[:,1]\n",
    "        aucs.append(roc_auc_score(y_valid, y_pred_proba))\n",
    "    \n",
    "    return np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "adf881a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-20 14:13:34,490] A new study created in memory with name: lgbm_opt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba63a7445524af18aa230cd4538bf42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:13:36,808] Trial 0 finished with value: 0.5931910052109008 and parameters: {'n_estimators': 1134, 'max_depth': 13, 'num_leaves': 32, 'learning_rate': 0.21554305624639344, 'subsample': 0.634663874188347, 'colsample_bytree': 0.7540057182782813, 'reg_alpha': 0.005738002926098198, 'reg_lambda': 0.0018475236119055347}. Best is trial 0 with value: 0.5931910052109008.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:13:41,612] Trial 1 finished with value: 0.6115211427775283 and parameters: {'n_estimators': 2572, 'max_depth': 13, 'num_leaves': 57, 'learning_rate': 0.045526981246353335, 'subsample': 0.9925243165679569, 'colsample_bytree': 0.7950110011107605, 'reg_alpha': 1.0828650185992128, 'reg_lambda': 7.271594436699448}. Best is trial 1 with value: 0.6115211427775283.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:13:46,707] Trial 2 finished with value: 0.6080330478465809 and parameters: {'n_estimators': 1047, 'max_depth': 17, 'num_leaves': 57, 'learning_rate': 0.03184052970326709, 'subsample': 0.7357759531049042, 'colsample_bytree': 0.8646177610833689, 'reg_alpha': 1.8882352146464514, 'reg_lambda': 0.17853959127838562}. Best is trial 1 with value: 0.6115211427775283.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:13:51,738] Trial 3 finished with value: 0.6020962333933007 and parameters: {'n_estimators': 2264, 'max_depth': 12, 'num_leaves': 59, 'learning_rate': 0.035760510701381275, 'subsample': 0.9823485668522511, 'colsample_bytree': 0.8157592798578709, 'reg_alpha': 0.0013878764277053628, 'reg_lambda': 0.013667562808030801}. Best is trial 1 with value: 0.6115211427775283.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:14:01,602] Trial 4 finished with value: 0.6121328119012948 and parameters: {'n_estimators': 1620, 'max_depth': 8, 'num_leaves': 63, 'learning_rate': 0.015409475456377102, 'subsample': 0.5023865308609524, 'colsample_bytree': 0.5885659999604294, 'reg_alpha': 1.0464848234869009, 'reg_lambda': 4.520140821451014}. Best is trial 4 with value: 0.6121328119012948.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[I 2025-12-20 14:14:04,665] Trial 5 finished with value: 0.5750001988755605 and parameters: {'n_estimators': 1438, 'max_depth': 10, 'num_leaves': 64, 'learning_rate': 0.2638772040323668, 'subsample': 0.8819065617916766, 'colsample_bytree': 0.9320715015876527, 'reg_alpha': 0.003492770361524102, 'reg_lambda': 0.64787378221502}. Best is trial 4 with value: 0.6121328119012948.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:14:15,572] Trial 6 finished with value: 0.6110087406864639 and parameters: {'n_estimators': 2900, 'max_depth': 13, 'num_leaves': 71, 'learning_rate': 0.010085673467205975, 'subsample': 0.5726814540109477, 'colsample_bytree': 0.6550882340979272, 'reg_alpha': 0.08542355170514021, 'reg_lambda': 1.1070277629635903}. Best is trial 4 with value: 0.6121328119012948.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[I 2025-12-20 14:14:18,434] Trial 7 finished with value: 0.603730392445003 and parameters: {'n_estimators': 2375, 'max_depth': 10, 'num_leaves': 48, 'learning_rate': 0.23634268952535295, 'subsample': 0.7433657092500086, 'colsample_bytree': 0.509232195291554, 'reg_alpha': 0.062104172756194745, 'reg_lambda': 0.3411821550200712}. Best is trial 4 with value: 0.6121328119012948.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:14:20,698] Trial 8 finished with value: 0.6088017057845061 and parameters: {'n_estimators': 1779, 'max_depth': 11, 'num_leaves': 17, 'learning_rate': 0.08599691544749885, 'subsample': 0.7867636940472902, 'colsample_bytree': 0.9848040316807318, 'reg_alpha': 0.18759786472694998, 'reg_lambda': 0.005174413735447289}. Best is trial 4 with value: 0.6121328119012948.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[I 2025-12-20 14:14:24,290] Trial 9 finished with value: 0.5937248871319292 and parameters: {'n_estimators': 1529, 'max_depth': 10, 'num_leaves': 68, 'learning_rate': 0.14106466925096212, 'subsample': 0.5391698329497654, 'colsample_bytree': 0.7662130120506299, 'reg_alpha': 0.00481318162121891, 'reg_lambda': 0.0038360926152711545}. Best is trial 4 with value: 0.6121328119012948.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[I 2025-12-20 14:14:32,877] Trial 10 finished with value: 0.613734237408607 and parameters: {'n_estimators': 2017, 'max_depth': 8, 'num_leaves': 41, 'learning_rate': 0.016377413392368857, 'subsample': 0.6511939521399001, 'colsample_bytree': 0.6147669963214244, 'reg_alpha': 9.98026588313809, 'reg_lambda': 9.416223773898695}. Best is trial 10 with value: 0.613734237408607.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[I 2025-12-20 14:14:43,263] Trial 11 finished with value: 0.614725207173464 and parameters: {'n_estimators': 1908, 'max_depth': 8, 'num_leaves': 40, 'learning_rate': 0.013076615900854217, 'subsample': 0.5022386449668421, 'colsample_bytree': 0.6028257517825053, 'reg_alpha': 9.116911078774594, 'reg_lambda': 7.2056677125477755}. Best is trial 11 with value: 0.614725207173464.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:14:50,180] Trial 12 finished with value: 0.613333781019946 and parameters: {'n_estimators': 2019, 'max_depth': 8, 'num_leaves': 33, 'learning_rate': 0.018699842353627805, 'subsample': 0.6400303128193059, 'colsample_bytree': 0.6513828134526749, 'reg_alpha': 7.223464294873412, 'reg_lambda': 2.474121964257705}. Best is trial 11 with value: 0.614725207173464.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:14:56,573] Trial 13 finished with value: 0.6133793177673935 and parameters: {'n_estimators': 1992, 'max_depth': 8, 'num_leaves': 39, 'learning_rate': 0.02060778465801366, 'subsample': 0.6357337270769661, 'colsample_bytree': 0.6561256961052002, 'reg_alpha': 9.261014233546083, 'reg_lambda': 0.037560757242541}. Best is trial 11 with value: 0.614725207173464.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:15:00,671] Trial 14 finished with value: 0.6116241908308628 and parameters: {'n_estimators': 2020, 'max_depth': 17, 'num_leaves': 23, 'learning_rate': 0.010768465149437299, 'subsample': 0.583460513157077, 'colsample_bytree': 0.50106434776639, 'reg_alpha': 2.9856185205806725, 'reg_lambda': 8.271353229698143}. Best is trial 11 with value: 0.614725207173464.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:15:06,490] Trial 15 finished with value: 0.6125226967715861 and parameters: {'n_estimators': 2288, 'max_depth': 9, 'num_leaves': 46, 'learning_rate': 0.024486183022222777, 'subsample': 0.69219079461168, 'colsample_bytree': 0.5894956393078982, 'reg_alpha': 0.3252365876779114, 'reg_lambda': 2.3362176587009986}. Best is trial 11 with value: 0.614725207173464.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:15:15,031] Trial 16 finished with value: 0.609889948358755 and parameters: {'n_estimators': 1801, 'max_depth': 15, 'num_leaves': 38, 'learning_rate': 0.01413187544898861, 'subsample': 0.5031071180822627, 'colsample_bytree': 0.7008382598148286, 'reg_alpha': 0.024453817538839507, 'reg_lambda': 0.06820072214161056}. Best is trial 11 with value: 0.614725207173464.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:15:19,451] Trial 17 finished with value: 0.6115472818892501 and parameters: {'n_estimators': 2603, 'max_depth': 9, 'num_leaves': 51, 'learning_rate': 0.06666146828667396, 'subsample': 0.8092308510599108, 'colsample_bytree': 0.5655639501065791, 'reg_alpha': 0.4536562217959936, 'reg_lambda': 1.117320196429052}. Best is trial 11 with value: 0.614725207173464.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:15:24,090] Trial 18 finished with value: 0.6115568136482807 and parameters: {'n_estimators': 1297, 'max_depth': 15, 'num_leaves': 27, 'learning_rate': 0.026246035893638598, 'subsample': 0.6978621334283468, 'colsample_bytree': 0.6992562008553055, 'reg_alpha': 3.7092456409125836, 'reg_lambda': 2.3007322665841463}. Best is trial 11 with value: 0.614725207173464.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:15:31,578] Trial 19 finished with value: 0.6125658073707066 and parameters: {'n_estimators': 1823, 'max_depth': 11, 'num_leaves': 40, 'learning_rate': 0.0143713849127599, 'subsample': 0.5809924397502164, 'colsample_bytree': 0.5645628806271324, 'reg_alpha': 9.248781847056078, 'reg_lambda': 9.815265140849663}. Best is trial 11 with value: 0.614725207173464.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[I 2025-12-20 14:15:36,375] Trial 20 finished with value: 0.6079510003891415 and parameters: {'n_estimators': 2120, 'max_depth': 9, 'num_leaves': 52, 'learning_rate': 0.05189157308098089, 'subsample': 0.89537357732596, 'colsample_bytree': 0.7086808727971479, 'reg_alpha': 0.8158814027687155, 'reg_lambda': 0.37869060592228526}. Best is trial 11 with value: 0.614725207173464.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:15:42,868] Trial 21 finished with value: 0.6133575021159527 and parameters: {'n_estimators': 1876, 'max_depth': 8, 'num_leaves': 40, 'learning_rate': 0.02172817040569022, 'subsample': 0.6324546672061081, 'colsample_bytree': 0.6564938428658696, 'reg_alpha': 9.417346707398295, 'reg_lambda': 0.04503863233004241}. Best is trial 11 with value: 0.614725207173464.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:15:48,563] Trial 22 finished with value: 0.6118138055166369 and parameters: {'n_estimators': 2148, 'max_depth': 8, 'num_leaves': 35, 'learning_rate': 0.01760759003136448, 'subsample': 0.6792864366783609, 'colsample_bytree': 0.6166410719955784, 'reg_alpha': 3.757053906355484, 'reg_lambda': 0.029415666073529027}. Best is trial 11 with value: 0.614725207173464.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:15:55,207] Trial 23 finished with value: 0.6100177857209246 and parameters: {'n_estimators': 1664, 'max_depth': 9, 'num_leaves': 42, 'learning_rate': 0.012476591840126835, 'subsample': 0.6091087157259638, 'colsample_bytree': 0.6246378085310205, 'reg_alpha': 3.7828163289521104, 'reg_lambda': 0.016217047926216692}. Best is trial 11 with value: 0.614725207173464.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:15:59,809] Trial 24 finished with value: 0.6137119169351382 and parameters: {'n_estimators': 1940, 'max_depth': 8, 'num_leaves': 29, 'learning_rate': 0.029971134230076815, 'subsample': 0.5458912883929181, 'colsample_bytree': 0.538963878556792, 'reg_alpha': 1.4717261794112324, 'reg_lambda': 0.19140024454485918}. Best is trial 11 with value: 0.614725207173464.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:16:04,226] Trial 25 finished with value: 0.6115028281409287 and parameters: {'n_estimators': 2404, 'max_depth': 11, 'num_leaves': 28, 'learning_rate': 0.031202709508674136, 'subsample': 0.5499644715933979, 'colsample_bytree': 0.5420587528144953, 'reg_alpha': 1.897013620666948, 'reg_lambda': 0.17596700859386213}. Best is trial 11 with value: 0.614725207173464.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:16:08,250] Trial 26 finished with value: 0.6164678959133768 and parameters: {'n_estimators': 1383, 'max_depth': 9, 'num_leaves': 15, 'learning_rate': 0.03809162270104497, 'subsample': 0.5346820447568432, 'colsample_bytree': 0.5351347426506272, 'reg_alpha': 1.7593079978587363, 'reg_lambda': 4.058618948031792}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:16:11,977] Trial 27 finished with value: 0.6111521742546705 and parameters: {'n_estimators': 1401, 'max_depth': 10, 'num_leaves': 18, 'learning_rate': 0.039856065702554365, 'subsample': 0.5030286592205657, 'colsample_bytree': 0.6171918647228188, 'reg_alpha': 0.48343077944551616, 'reg_lambda': 5.019169752141596}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[I 2025-12-20 14:16:16,641] Trial 28 finished with value: 0.6122087288962481 and parameters: {'n_estimators': 1241, 'max_depth': 9, 'num_leaves': 75, 'learning_rate': 0.07324164081949117, 'subsample': 0.5983576368764145, 'colsample_bytree': 0.5278843092665976, 'reg_alpha': 5.491872176521246, 'reg_lambda': 3.4599590484686047}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:16:19,152] Trial 29 finished with value: 0.6093927701229632 and parameters: {'n_estimators': 1015, 'max_depth': 12, 'num_leaves': 24, 'learning_rate': 0.11241338200050251, 'subsample': 0.5445813385773917, 'colsample_bytree': 0.7360718978466867, 'reg_alpha': 2.3561806476527143, 'reg_lambda': 1.7792471712797262}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:16:24,120] Trial 30 finished with value: 0.6098930375463456 and parameters: {'n_estimators': 1195, 'max_depth': 14, 'num_leaves': 15, 'learning_rate': 0.012115217906488764, 'subsample': 0.6618237899148296, 'colsample_bytree': 0.5820176989445586, 'reg_alpha': 0.017516312764028485, 'reg_lambda': 0.8072716228773514}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:16:29,132] Trial 31 finished with value: 0.6122520884792284 and parameters: {'n_estimators': 1665, 'max_depth': 8, 'num_leaves': 31, 'learning_rate': 0.027731521881694234, 'subsample': 0.5400792589678796, 'colsample_bytree': 0.5485756737269974, 'reg_alpha': 1.2994552644442912, 'reg_lambda': 0.0012099544987789965}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:16:33,014] Trial 32 finished with value: 0.6141402943681896 and parameters: {'n_estimators': 1927, 'max_depth': 9, 'num_leaves': 22, 'learning_rate': 0.04155085277926119, 'subsample': 0.5282084531645485, 'colsample_bytree': 0.5305133752812493, 'reg_alpha': 4.775577994421145, 'reg_lambda': 6.07544304647853}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:16:36,652] Trial 33 finished with value: 0.6153141310501409 and parameters: {'n_estimators': 2629, 'max_depth': 9, 'num_leaves': 21, 'learning_rate': 0.041918456940397274, 'subsample': 0.5283660625668973, 'colsample_bytree': 0.504529421303805, 'reg_alpha': 5.7931895782576435, 'reg_lambda': 5.283231385541156}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:16:40,485] Trial 34 finished with value: 0.6152485768503284 and parameters: {'n_estimators': 2761, 'max_depth': 10, 'num_leaves': 21, 'learning_rate': 0.04845118462810032, 'subsample': 0.5099362937948132, 'colsample_bytree': 0.500321540976868, 'reg_alpha': 4.909172669704351, 'reg_lambda': 4.554325219937818}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:16:43,939] Trial 35 finished with value: 0.6125144263071537 and parameters: {'n_estimators': 2966, 'max_depth': 10, 'num_leaves': 20, 'learning_rate': 0.056165146361879414, 'subsample': 0.5644581341573909, 'colsample_bytree': 0.5003630119449237, 'reg_alpha': 0.6948433339797332, 'reg_lambda': 3.7525276770973335}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:16:47,374] Trial 36 finished with value: 0.61158572622329 and parameters: {'n_estimators': 2748, 'max_depth': 11, 'num_leaves': 25, 'learning_rate': 0.051648402225069424, 'subsample': 0.5123432958255232, 'colsample_bytree': 0.5855853659753956, 'reg_alpha': 2.2971179506436386, 'reg_lambda': 1.7306812910343587}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:16:49,340] Trial 37 finished with value: 0.6092554278094368 and parameters: {'n_estimators': 2602, 'max_depth': 12, 'num_leaves': 15, 'learning_rate': 0.14701872267822538, 'subsample': 0.6073280615176045, 'colsample_bytree': 0.8396323001045997, 'reg_alpha': 0.18893288564409402, 'reg_lambda': 4.9031040689942404}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:16:53,202] Trial 38 finished with value: 0.6133988869632356 and parameters: {'n_estimators': 2792, 'max_depth': 10, 'num_leaves': 19, 'learning_rate': 0.036276833702774916, 'subsample': 0.5267590199147422, 'colsample_bytree': 0.5179487869139053, 'reg_alpha': 5.345304595681783, 'reg_lambda': 0.500035780169133}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:16:56,318] Trial 39 finished with value: 0.6120174133713439 and parameters: {'n_estimators': 2757, 'max_depth': 9, 'num_leaves': 21, 'learning_rate': 0.0862328511974221, 'subsample': 0.9496354822324863, 'colsample_bytree': 0.5607193704543779, 'reg_alpha': 1.0991618928149878, 'reg_lambda': 1.3113807405603386}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:16:59,479] Trial 40 finished with value: 0.6148641174471019 and parameters: {'n_estimators': 2482, 'max_depth': 10, 'num_leaves': 26, 'learning_rate': 0.06274988212277187, 'subsample': 0.5593108809572022, 'colsample_bytree': 0.9108373585318188, 'reg_alpha': 5.918716302605181, 'reg_lambda': 3.1398374644706646}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:02,644] Trial 41 finished with value: 0.6142847776943149 and parameters: {'n_estimators': 2521, 'max_depth': 10, 'num_leaves': 26, 'learning_rate': 0.061166274631706805, 'subsample': 0.5659793647477094, 'colsample_bytree': 0.8944631672983436, 'reg_alpha': 5.920091683701357, 'reg_lambda': 6.032859111965108}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:06,387] Trial 42 finished with value: 0.6109791469557947 and parameters: {'n_estimators': 2472, 'max_depth': 9, 'num_leaves': 34, 'learning_rate': 0.0479548079312693, 'subsample': 0.5005761272529429, 'colsample_bytree': 0.9640673499138924, 'reg_alpha': 2.762446358441138, 'reg_lambda': 3.010991883262013}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:09,107] Trial 43 finished with value: 0.6101257064261147 and parameters: {'n_estimators': 2685, 'max_depth': 11, 'num_leaves': 30, 'learning_rate': 0.09775600412129927, 'subsample': 0.5250008772888985, 'colsample_bytree': 0.7939233426069289, 'reg_alpha': 1.9435858458580195, 'reg_lambda': 4.28704583981055}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:12,037] Trial 44 finished with value: 0.6148519160780358 and parameters: {'n_estimators': 2841, 'max_depth': 10, 'num_leaves': 16, 'learning_rate': 0.076734605061221, 'subsample': 0.5936565795595559, 'colsample_bytree': 0.9027192236216844, 'reg_alpha': 7.03393445743978, 'reg_lambda': 7.346015951187314}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:14,864] Trial 45 finished with value: 0.6128337001323562 and parameters: {'n_estimators': 2890, 'max_depth': 11, 'num_leaves': 17, 'learning_rate': 0.07408515176098372, 'subsample': 0.5989390273225005, 'colsample_bytree': 0.8890980788461665, 'reg_alpha': 5.990296849429864, 'reg_lambda': 0.8240553549398099}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:18,234] Trial 46 finished with value: 0.6119407455177017 and parameters: {'n_estimators': 2881, 'max_depth': 10, 'num_leaves': 15, 'learning_rate': 0.036210806267904336, 'subsample': 0.5639995945662135, 'colsample_bytree': 0.9323173607712519, 'reg_alpha': 0.0010725319497607419, 'reg_lambda': 1.506243451184493}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:20,458] Trial 47 finished with value: 0.609322593220392 and parameters: {'n_estimators': 2664, 'max_depth': 13, 'num_leaves': 21, 'learning_rate': 0.17325102704548165, 'subsample': 0.7762075313862831, 'colsample_bytree': 0.8655613158829537, 'reg_alpha': 3.430837366491296, 'reg_lambda': 9.790329460976292}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:23,737] Trial 48 finished with value: 0.6098583081275036 and parameters: {'n_estimators': 2969, 'max_depth': 10, 'num_leaves': 18, 'learning_rate': 0.043225011836758184, 'subsample': 0.7129481508732086, 'colsample_bytree': 0.9385983378062508, 'reg_alpha': 1.5111650777104728, 'reg_lambda': 2.9099663976033425}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:26,366] Trial 49 finished with value: 0.6102950692844203 and parameters: {'n_estimators': 2326, 'max_depth': 12, 'num_leaves': 23, 'learning_rate': 0.11201545082685455, 'subsample': 0.6176361596998272, 'colsample_bytree': 0.8182143547547476, 'reg_alpha': 0.05062572608189991, 'reg_lambda': 6.650622591960266}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:29,336] Trial 50 finished with value: 0.6101075304410195 and parameters: {'n_estimators': 2836, 'max_depth': 10, 'num_leaves': 25, 'learning_rate': 0.06619435790942933, 'subsample': 0.579570337571828, 'colsample_bytree': 0.9121355325351437, 'reg_alpha': 0.8032615269121115, 'reg_lambda': 1.9236024012185793}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:32,191] Trial 51 finished with value: 0.6148158122110962 and parameters: {'n_estimators': 2214, 'max_depth': 9, 'num_leaves': 19, 'learning_rate': 0.08670803498521076, 'subsample': 0.5150084463212035, 'colsample_bytree': 0.9694874667463593, 'reg_alpha': 7.1144017876504195, 'reg_lambda': 6.045179436783671}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:34,937] Trial 52 finished with value: 0.6142220092898645 and parameters: {'n_estimators': 2178, 'max_depth': 9, 'num_leaves': 17, 'learning_rate': 0.08445774211614109, 'subsample': 0.5215620244042374, 'colsample_bytree': 0.9803520980783302, 'reg_alpha': 6.488264429648828, 'reg_lambda': 3.9981749306707854}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:38,228] Trial 53 finished with value: 0.6141783053764059 and parameters: {'n_estimators': 2475, 'max_depth': 9, 'num_leaves': 21, 'learning_rate': 0.057959388451958846, 'subsample': 0.5617704250938884, 'colsample_bytree': 0.999340863656333, 'reg_alpha': 4.831162979881434, 'reg_lambda': 7.137561759803561}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:41,371] Trial 54 finished with value: 0.6142522802844707 and parameters: {'n_estimators': 2550, 'max_depth': 10, 'num_leaves': 19, 'learning_rate': 0.04663824183104825, 'subsample': 0.5904821176778339, 'colsample_bytree': 0.8610347675072832, 'reg_alpha': 7.241619788006811, 'reg_lambda': 2.7339686503739644}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:44,039] Trial 55 finished with value: 0.6100819372209567 and parameters: {'n_estimators': 2225, 'max_depth': 11, 'num_leaves': 27, 'learning_rate': 0.10006858913140458, 'subsample': 0.5298012952640186, 'colsample_bytree': 0.9614636697439399, 'reg_alpha': 2.770564569155259, 'reg_lambda': 5.05132676373522}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:46,392] Trial 56 finished with value: 0.6108194827916644 and parameters: {'n_estimators': 2367, 'max_depth': 9, 'num_leaves': 15, 'learning_rate': 0.07014793427885037, 'subsample': 0.5509451017832213, 'colsample_bytree': 0.9191108607014109, 'reg_alpha': 0.0027501215850536595, 'reg_lambda': 0.003641036322812668}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:49,197] Trial 57 finished with value: 0.6114095052266655 and parameters: {'n_estimators': 2679, 'max_depth': 10, 'num_leaves': 23, 'learning_rate': 0.08174909597905712, 'subsample': 0.6255894775349589, 'colsample_bytree': 0.7668842196125658, 'reg_alpha': 4.215685524222198, 'reg_lambda': 1.0352968582937903}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:53,565] Trial 58 finished with value: 0.6153938045317753 and parameters: {'n_estimators': 2091, 'max_depth': 8, 'num_leaves': 17, 'learning_rate': 0.033994089296473906, 'subsample': 0.580202143771839, 'colsample_bytree': 0.9511698976078012, 'reg_alpha': 7.5626914797301135, 'reg_lambda': 7.744641646845251}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:17:57,977] Trial 59 finished with value: 0.6145846901757643 and parameters: {'n_estimators': 1526, 'max_depth': 8, 'num_leaves': 17, 'learning_rate': 0.033754479297750994, 'subsample': 0.6559956432572523, 'colsample_bytree': 0.943212453287245, 'reg_alpha': 9.058729651751769, 'reg_lambda': 9.781349233879931}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:18:03,313] Trial 60 finished with value: 0.6124236885053134 and parameters: {'n_estimators': 2823, 'max_depth': 8, 'num_leaves': 32, 'learning_rate': 0.02243508777546335, 'subsample': 0.5850586596359322, 'colsample_bytree': 0.8974030440867342, 'reg_alpha': 3.3077971173855323, 'reg_lambda': 2.265965277263698}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:18:06,852] Trial 61 finished with value: 0.6133858450708015 and parameters: {'n_estimators': 2090, 'max_depth': 9, 'num_leaves': 20, 'learning_rate': 0.06149568872307561, 'subsample': 0.5158309037906972, 'colsample_bytree': 0.958533251045148, 'reg_alpha': 7.379445409988582, 'reg_lambda': 6.845819625928817}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:18:11,498] Trial 62 finished with value: 0.6155662718036823 and parameters: {'n_estimators': 2438, 'max_depth': 8, 'num_leaves': 17, 'learning_rate': 0.037635880454815154, 'subsample': 0.5528774332808662, 'colsample_bytree': 0.5157377268619869, 'reg_alpha': 4.489134308014869, 'reg_lambda': 3.7004810764855676}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:18:17,447] Trial 63 finished with value: 0.6110362044403976 and parameters: {'n_estimators': 2447, 'max_depth': 8, 'num_leaves': 59, 'learning_rate': 0.040805125433714735, 'subsample': 0.8293703736736353, 'colsample_bytree': 0.5226821244789952, 'reg_alpha': 1.7896069963572039, 'reg_lambda': 3.5331509504748206}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:18:21,518] Trial 64 finished with value: 0.6139387780647814 and parameters: {'n_estimators': 2627, 'max_depth': 8, 'num_leaves': 16, 'learning_rate': 0.028651502730434143, 'subsample': 0.5547659426930975, 'colsample_bytree': 0.5621151301793663, 'reg_alpha': 4.27398276094579, 'reg_lambda': 4.452783043790319}. Best is trial 26 with value: 0.6164678959133768.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:18:25,278] Trial 65 finished with value: 0.6166717389391679 and parameters: {'n_estimators': 2532, 'max_depth': 8, 'num_leaves': 24, 'learning_rate': 0.04969005464251589, 'subsample': 0.5768277171011928, 'colsample_bytree': 0.5118861223960542, 'reg_alpha': 9.775397894212075, 'reg_lambda': 2.453162678283216}. Best is trial 65 with value: 0.6166717389391679.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:18:28,980] Trial 66 finished with value: 0.6161245506998256 and parameters: {'n_estimators': 2341, 'max_depth': 8, 'num_leaves': 37, 'learning_rate': 0.0503146986599726, 'subsample': 0.5395321517013112, 'colsample_bytree': 0.5001972995324632, 'reg_alpha': 2.980120836431799, 'reg_lambda': 1.3469808338624873}. Best is trial 65 with value: 0.6166717389391679.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:18:33,579] Trial 67 finished with value: 0.6143863094221075 and parameters: {'n_estimators': 2333, 'max_depth': 8, 'num_leaves': 43, 'learning_rate': 0.05076255962072038, 'subsample': 0.5354712279388589, 'colsample_bytree': 0.5127855279099589, 'reg_alpha': 3.1475599908379275, 'reg_lambda': 0.6253265486760106}. Best is trial 65 with value: 0.6166717389391679.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:18:38,878] Trial 68 finished with value: 0.6156768950813742 and parameters: {'n_estimators': 2083, 'max_depth': 8, 'num_leaves': 37, 'learning_rate': 0.03770947986617349, 'subsample': 0.5407165830585342, 'colsample_bytree': 0.5483818671465464, 'reg_alpha': 9.61871741652578, 'reg_lambda': 1.9979070285374418}. Best is trial 65 with value: 0.6166717389391679.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[I 2025-12-20 14:18:44,285] Trial 69 finished with value: 0.6159584164896151 and parameters: {'n_estimators': 2064, 'max_depth': 8, 'num_leaves': 36, 'learning_rate': 0.03736507604236195, 'subsample': 0.5739648148717765, 'colsample_bytree': 0.5482553803439284, 'reg_alpha': 9.861364924576339, 'reg_lambda': 0.30048353077035794}. Best is trial 65 with value: 0.6166717389391679.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:18:50,074] Trial 70 finished with value: 0.6145641943107589 and parameters: {'n_estimators': 2054, 'max_depth': 8, 'num_leaves': 38, 'learning_rate': 0.03390017463375002, 'subsample': 0.6442146654724168, 'colsample_bytree': 0.6363036836192145, 'reg_alpha': 9.863074118307322, 'reg_lambda': 0.3274997184995919}. Best is trial 65 with value: 0.6166717389391679.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[I 2025-12-20 14:18:56,062] Trial 71 finished with value: 0.6158930937650522 and parameters: {'n_estimators': 2262, 'max_depth': 8, 'num_leaves': 35, 'learning_rate': 0.02492780786605407, 'subsample': 0.579230636173448, 'colsample_bytree': 0.550163759813779, 'reg_alpha': 9.727908476348775, 'reg_lambda': 1.2696818389547557}. Best is trial 65 with value: 0.6166717389391679.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:19:02,121] Trial 72 finished with value: 0.616233993611344 and parameters: {'n_estimators': 2261, 'max_depth': 8, 'num_leaves': 35, 'learning_rate': 0.02350431189693827, 'subsample': 0.5753863490139457, 'colsample_bytree': 0.5458944112298622, 'reg_alpha': 8.400204584538365, 'reg_lambda': 0.16156838463645787}. Best is trial 65 with value: 0.6166717389391679.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[I 2025-12-20 14:19:08,841] Trial 73 finished with value: 0.6169595791915335 and parameters: {'n_estimators': 2315, 'max_depth': 8, 'num_leaves': 36, 'learning_rate': 0.026082379503893353, 'subsample': 0.6150798682646407, 'colsample_bytree': 0.5489265043486458, 'reg_alpha': 9.373651844220582, 'reg_lambda': 0.09686732414333193}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:19:13,456] Trial 74 finished with value: 0.6130049485179629 and parameters: {'n_estimators': 2252, 'max_depth': 8, 'num_leaves': 37, 'learning_rate': 0.0238518311350988, 'subsample': 0.6141894795703878, 'colsample_bytree': 0.5429695881221701, 'reg_alpha': 2.276827402576324, 'reg_lambda': 0.12390738585648724}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:19:19,878] Trial 75 finished with value: 0.6146934349136208 and parameters: {'n_estimators': 2297, 'max_depth': 8, 'num_leaves': 36, 'learning_rate': 0.019747936448031154, 'subsample': 0.5752974916542524, 'colsample_bytree': 0.6017724978451333, 'reg_alpha': 9.978807336370949, 'reg_lambda': 0.0890550243657362}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:19:26,411] Trial 76 finished with value: 0.6140154717803895 and parameters: {'n_estimators': 2391, 'max_depth': 8, 'num_leaves': 46, 'learning_rate': 0.02517304364298753, 'subsample': 0.6277375094692098, 'colsample_bytree': 0.570558470144298, 'reg_alpha': 8.313675125580867, 'reg_lambda': 0.16849206277031614}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:19:32,724] Trial 77 finished with value: 0.6111883326211173 and parameters: {'n_estimators': 2171, 'max_depth': 17, 'num_leaves': 33, 'learning_rate': 0.01781228024901846, 'subsample': 0.6001784472123343, 'colsample_bytree': 0.5513564430553489, 'reg_alpha': 0.23678849732158494, 'reg_lambda': 0.30869043477384644}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:19:37,285] Trial 78 finished with value: 0.60617474765876 and parameters: {'n_estimators': 1967, 'max_depth': 8, 'num_leaves': 43, 'learning_rate': 0.029840932926719556, 'subsample': 0.539963830407222, 'colsample_bytree': 0.5296751198803703, 'reg_alpha': 0.11754025652779604, 'reg_lambda': 0.06710930661612939}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:19:43,234] Trial 79 finished with value: 0.6159202225201205 and parameters: {'n_estimators': 1856, 'max_depth': 16, 'num_leaves': 35, 'learning_rate': 0.026254951750802114, 'subsample': 0.6763272800219048, 'colsample_bytree': 0.5784540588375087, 'reg_alpha': 9.978344159076185, 'reg_lambda': 0.13239131651513997}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:19:48,771] Trial 80 finished with value: 0.6126103148213711 and parameters: {'n_estimators': 1115, 'max_depth': 16, 'num_leaves': 35, 'learning_rate': 0.027224098653144284, 'subsample': 0.6694086377970792, 'colsample_bytree': 0.5973760476116958, 'reg_alpha': 3.752441901752722, 'reg_lambda': 0.2413854018774601}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:19:55,520] Trial 81 finished with value: 0.6150004766070374 and parameters: {'n_estimators': 1853, 'max_depth': 15, 'num_leaves': 40, 'learning_rate': 0.021648864578979868, 'subsample': 0.5747884297414827, 'colsample_bytree': 0.5762880325595146, 'reg_alpha': 9.92072293661863, 'reg_lambda': 0.1245833775442212}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:20:02,486] Trial 82 finished with value: 0.6148258515186098 and parameters: {'n_estimators': 2134, 'max_depth': 14, 'num_leaves': 30, 'learning_rate': 0.015856481314089885, 'subsample': 0.6200339858568362, 'colsample_bytree': 0.5515340887890879, 'reg_alpha': 5.356901024267104, 'reg_lambda': 0.42518334010392045}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:20:08,208] Trial 83 finished with value: 0.6117588644895304 and parameters: {'n_estimators': 1393, 'max_depth': 8, 'num_leaves': 38, 'learning_rate': 0.024361789439941425, 'subsample': 0.684298828911322, 'colsample_bytree': 0.5361287172393571, 'reg_alpha': 0.010298119430278696, 'reg_lambda': 0.060393726216401225}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:20:14,240] Trial 84 finished with value: 0.6127558049692249 and parameters: {'n_estimators': 2289, 'max_depth': 16, 'num_leaves': 49, 'learning_rate': 0.03860387438457957, 'subsample': 0.6424814685391694, 'colsample_bytree': 0.5545587318592305, 'reg_alpha': 7.709927115694309, 'reg_lambda': 0.22733372916458247}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:20:18,189] Trial 85 finished with value: 0.6138205712614546 and parameters: {'n_estimators': 1782, 'max_depth': 8, 'num_leaves': 34, 'learning_rate': 0.04315664038382617, 'subsample': 0.7315904091444584, 'colsample_bytree': 0.6724766250675068, 'reg_alpha': 6.029018072291072, 'reg_lambda': 0.024508152102315564}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:20:24,255] Trial 86 finished with value: 0.6143481805667703 and parameters: {'n_estimators': 1714, 'max_depth': 9, 'num_leaves': 36, 'learning_rate': 0.03101190267250865, 'subsample': 0.6052100957985285, 'colsample_bytree': 0.5905630843293813, 'reg_alpha': 7.837076653314808, 'reg_lambda': 0.9184888588092309}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:20:29,405] Trial 87 finished with value: 0.6137064504120543 and parameters: {'n_estimators': 2002, 'max_depth': 8, 'num_leaves': 32, 'learning_rate': 0.026355442892087556, 'subsample': 0.5673035551742637, 'colsample_bytree': 0.5724387247209475, 'reg_alpha': 2.6986790530774925, 'reg_lambda': 0.08547204569515228}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:20:35,830] Trial 88 finished with value: 0.6151922564441883 and parameters: {'n_estimators': 2051, 'max_depth': 9, 'num_leaves': 29, 'learning_rate': 0.020348985781245443, 'subsample': 0.5440150961120417, 'colsample_bytree': 0.5270133279127694, 'reg_alpha': 4.58978956715649, 'reg_lambda': 0.12618508962069233}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:20:40,516] Trial 89 finished with value: 0.6130905946147271 and parameters: {'n_estimators': 2204, 'max_depth': 8, 'num_leaves': 41, 'learning_rate': 0.05451856437992425, 'subsample': 0.7067723099726677, 'colsample_bytree': 0.5391039189923094, 'reg_alpha': 6.198208231366564, 'reg_lambda': 0.6157841800099076}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:20:45,151] Trial 90 finished with value: 0.6132331521316157 and parameters: {'n_estimators': 2251, 'max_depth': 9, 'num_leaves': 44, 'learning_rate': 0.03173919798068576, 'subsample': 0.592001874438611, 'colsample_bytree': 0.5106415900829305, 'reg_alpha': 3.6159387302139736, 'reg_lambda': 1.2822487335544257}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:20:50,015] Trial 91 finished with value: 0.6129634299891709 and parameters: {'n_estimators': 2341, 'max_depth': 8, 'num_leaves': 39, 'learning_rate': 0.036710487319873635, 'subsample': 0.5532664703331618, 'colsample_bytree': 0.5157750529950089, 'reg_alpha': 4.937794366439109, 'reg_lambda': 2.091978765474334}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:20:54,319] Trial 92 finished with value: 0.6134511868929765 and parameters: {'n_estimators': 2433, 'max_depth': 8, 'num_leaves': 34, 'learning_rate': 0.04556812829083318, 'subsample': 0.5398454248284816, 'colsample_bytree': 0.5236305163246153, 'reg_alpha': 8.266366825286033, 'reg_lambda': 1.455924601023929}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:20:59,926] Trial 93 finished with value: 0.6153073255932978 and parameters: {'n_estimators': 1320, 'max_depth': 8, 'num_leaves': 36, 'learning_rate': 0.023099261528970093, 'subsample': 0.5672137345901689, 'colsample_bytree': 0.5435178002491634, 'reg_alpha': 4.3994186814613165, 'reg_lambda': 1.6543829330903135}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:21:04,712] Trial 94 finished with value: 0.6152635889967056 and parameters: {'n_estimators': 2520, 'max_depth': 9, 'num_leaves': 38, 'learning_rate': 0.029155761399817223, 'subsample': 0.5557441812042188, 'colsample_bytree': 0.5019484308194954, 'reg_alpha': 5.954045447178301, 'reg_lambda': 0.04714433659492513}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:21:10,013] Trial 95 finished with value: 0.6155778477049438 and parameters: {'n_estimators': 2411, 'max_depth': 8, 'num_leaves': 31, 'learning_rate': 0.03833933101714933, 'subsample': 0.5873475992972524, 'colsample_bytree': 0.5620833948995265, 'reg_alpha': 6.902282820264137, 'reg_lambda': 0.1429184205602135}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:21:15,215] Trial 96 finished with value: 0.6146501604733223 and parameters: {'n_estimators': 2377, 'max_depth': 14, 'num_leaves': 31, 'learning_rate': 0.0323441812038107, 'subsample': 0.6113137969284672, 'colsample_bytree': 0.5618240006367357, 'reg_alpha': 8.212463031514206, 'reg_lambda': 0.2617573163026461}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:21:21,083] Trial 97 finished with value: 0.6136273885239005 and parameters: {'n_estimators': 1893, 'max_depth': 9, 'num_leaves': 33, 'learning_rate': 0.018442396587156427, 'subsample': 0.5902580506593516, 'colsample_bytree': 0.5870590749725614, 'reg_alpha': 9.833886189656951, 'reg_lambda': 0.14399995079392927}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:21:25,682] Trial 98 finished with value: 0.6146254360490238 and parameters: {'n_estimators': 1563, 'max_depth': 8, 'num_leaves': 28, 'learning_rate': 0.03906333846271069, 'subsample': 0.5739333063334494, 'colsample_bytree': 0.6065371310940891, 'reg_alpha': 6.517142720795423, 'reg_lambda': 0.10575366331950832}. Best is trial 73 with value: 0.6169595791915335.\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[I 2025-12-20 14:21:29,906] Trial 99 finished with value: 0.6075416630498381 and parameters: {'n_estimators': 2120, 'max_depth': 9, 'num_leaves': 41, 'learning_rate': 0.04957215927093285, 'subsample': 0.6320093524303966, 'colsample_bytree': 0.6295089375143883, 'reg_alpha': 0.4896711613592415, 'reg_lambda': 0.4489298908241649}. Best is trial 73 with value: 0.6169595791915335.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=\"lgbm_opt\", direction=\"maximize\")\n",
    "study.optimize(objective_lgbm, n_trials=100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "21981ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value (F1): 0.6169595791915335\n",
      "Best params: {'n_estimators': 2315, 'max_depth': 8, 'num_leaves': 36, 'learning_rate': 0.026082379503893353, 'subsample': 0.6150798682646407, 'colsample_bytree': 0.5489265043486458, 'reg_alpha': 9.373651844220582, 'reg_lambda': 0.09686732414333193}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best value (F1):\", study.best_value)\n",
    "print(\"Best params:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb94c921",
   "metadata": {},
   "source": [
    "## OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27378f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2023\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Info] Number of positive: 1458, number of negative: 38542\n",
      "[LightGBM] [Info] Total Bins 2020\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036450 -> initscore=-3.274683\n",
      "[LightGBM] [Info] Start training from score -3.274683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Info] Number of positive: 1457, number of negative: 38543\n",
      "[LightGBM] [Info] Total Bins 2025\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036425 -> initscore=-3.275395\n",
      "[LightGBM] [Info] Start training from score -3.275395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "OOF ROC-AUC: 0.6173446846557262\n",
      "OOF PR-AUC (Average Precision): 0.060980145651406054\n"
     ]
    }
   ],
   "source": [
    "oof_proba = np.zeros(len(X), dtype=float)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=21)\n",
    "\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(cv.split(X, y), 1):\n",
    "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "    model = lightgbm.LGBMClassifier(**study.best_trial.params, force_row_wise=True,\n",
    "                                   n_jobs=-1, objective='binary', random_state=23)\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[lightgbm.early_stopping(80, verbose=False)]\n",
    "    )\n",
    "\n",
    "    oof_proba[va_idx] = model.predict_proba(X_va)[:, 1]\n",
    "\n",
    "print(\"\\nOOF ROC-AUC:\", roc_auc_score(y, oof_proba))\n",
    "print(\"OOF PR-AUC (Average Precision):\", average_precision_score(y, oof_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd78ee6",
   "metadata": {},
   "source": [
    "## Find best treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "f5c3e649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best threshold: 0.04933110367892977\n",
      "OOF Best F1: 0.1048951048951049\n",
      "\n",
      "Confusion matrix:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[41599,  6579],\n",
       "       [ 1357,   465]])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = np.linspace(0.01, 0.99, 300)\n",
    "\n",
    "f1s = []\n",
    "for t in thresholds:\n",
    "    pred = (oof_proba >= t).astype(int)\n",
    "    f1s.append(f1_score(y, pred))\n",
    "\n",
    "best_t = float(thresholds[int(np.argmax(f1s))])\n",
    "best_f1 = float(np.max(f1s))\n",
    "\n",
    "print(\"\\nBest threshold:\", best_t)\n",
    "print(\"OOF Best F1:\", best_f1)\n",
    "\n",
    "# quick diagnostics at best threshold\n",
    "oof_pred = (oof_proba >= best_t).astype(int)\n",
    "print(\"\\nConfusion matrix:\\n\")\n",
    "confusion_matrix(y, oof_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "e934c258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9684    0.8634    0.9129     48178\n",
      "           1     0.0660    0.2552    0.1049      1822\n",
      "\n",
      "    accuracy                         0.8413     50000\n",
      "   macro avg     0.5172    0.5593    0.5089     50000\n",
      "weighted avg     0.9355    0.8413    0.8835     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification report:\\n\", classification_report(y, oof_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028cf5c9",
   "metadata": {},
   "source": [
    "## Precision–Recall curve plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "a9133c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, pr_thresholds = precision_recall_curve(y, oof_proba)\n",
    "pr_auc = average_precision_score(y, oof_proba)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(f\"Precision–Recall Curve | PR-AUC(AP)={pr_auc:.5f}\")\n",
    "plt.grid()\n",
    "\n",
    "#plot F1 vs threshold\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(thresholds, f1s)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"F1\")\n",
    "plt.title(f\"F1 vs Threshold | best_t={best_t:.3f}, best_f1={best_f1:.5f}\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "b941159c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04939698492462312 0.10525124490719782\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.linspace(0.01, 0.99, 200)\n",
    "\n",
    "f1_scores = [\n",
    "    f1_score(y, (oof_proba >= t).astype(int))\n",
    "    for t in thresholds\n",
    "]\n",
    "\n",
    "best_t = thresholds[np.argmax(f1_scores)]\n",
    "best_f1 = max(f1_scores)\n",
    "\n",
    "print(best_t, best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd0b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1822, number of negative: 48178\n",
      "[LightGBM] [Info] Total Bins 2028\n",
      "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036440 -> initscore=-3.274968\n",
      "[LightGBM] [Info] Start training from score -3.274968\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-18 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-18 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-18 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-18 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-18 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-18 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-18 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-18 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-18 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(colsample_bytree=0.5489265043486458, force_row_wise=True,\n",
       "               learning_rate=0.026082379503893353, max_depth=8,\n",
       "               n_estimators=2315, n_jobs=-1, num_leaves=36, objective=&#x27;binary&#x27;,\n",
       "               random_state=23, reg_alpha=9.373651844220582,\n",
       "               reg_lambda=0.09686732414333193, subsample=0.6150798682646407)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('boosting_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">boosting_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gbdt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_leaves&nbsp;</td>\n",
       "            <td class=\"value\">36</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.026082379503893353</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">2315</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_for_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_for_bin&nbsp;</td>\n",
       "            <td class=\"value\">200000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_split_gain',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_split_gain&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_samples&nbsp;</td>\n",
       "            <td class=\"value\">20</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.6150798682646407</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_freq',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_freq&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.5489265043486458</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">9.373651844220582</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">0.09686732414333193</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">23</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;split&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('force_row_wise',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">force_row_wise&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.5489265043486458, force_row_wise=True,\n",
       "               learning_rate=0.026082379503893353, max_depth=8,\n",
       "               n_estimators=2315, n_jobs=-1, num_leaves=36, objective='binary',\n",
       "               random_state=23, reg_alpha=9.373651844220582,\n",
       "               reg_lambda=0.09686732414333193, subsample=0.6150798682646407)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf = lightgbm.LGBMClassifier(**study.best_trial.params, force_row_wise=True,\n",
    "                                   n_jobs=-1, objective='binary', random_state=23)\n",
    "\n",
    "lgbm_clf.fit(X, y, callbacks=[lightgbm.log_evaluation(period=0, show_stdv=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "2358aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lgbm_clf.predict_proba(fe_test)[:, 1]\n",
    "result = pd.DataFrame(data={'id':raw_test['id'], 'target':(preds >= best_t).astype(int)})\n",
    "result.to_csv(\"submission_exam.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "45fe1ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fi = list(zip(lgbm_clf.feature_names_in_, lgbm_clf.feature_importances_))\n",
    "fi = sorted(fi, key=lambda x: x[1])\n",
    "\n",
    "features = [x[0] for x in fi]\n",
    "importances = [x[1] for x in fi]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(features[-15:], importances[-15:])\n",
    "plt.grid(axis='x')\n",
    "plt.title('Feature importance LightGBM, top 15')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216fc2e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1939bbd8",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
